{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6d3011-8e5d-4d2d-9e48-c44c947a321c",
   "metadata": {},
   "source": [
    "<img src=\"./img/hpe_logo.png\" alt=\"HPE Logo\" width=\"125\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3033d6-3d69-4911-968a-26f90c2ff764",
   "metadata": {},
   "source": [
    "<h1>HPE ML Platform Workshop - Inferencing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cee4a-a3c1-48b5-86b9-b33b50de586b",
   "metadata": {},
   "source": [
    "<img src='img/platform_step03_deployment.png' width='1200'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fd494-142c-4341-b928-df7bebfa4954",
   "metadata": {},
   "source": [
    "<h3>Import modules and define functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995591f-539f-4b79-8304-3492b7e7eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import uuid\n",
    "import torch\n",
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8056db-801d-4dcd-8353-bc1e98e26244",
   "metadata": {},
   "source": [
    "<h3>Step 1: Setting up connection details to KServe and defining support functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30745d-d9e4-4a81-8133-e8e97fe26daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Set Variables\n",
    "config_obj = ConfigParser()\n",
    "config_obj.read(\"./utils/config.ini\")\n",
    "\n",
    "model_name = config_obj['PDK_INFO']['model_name']\n",
    "ingress_host = config_obj['PDK_INFO']['ingress_host']\n",
    "ingress_port = config_obj['PDK_INFO']['ingress_port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112e2ad-b337-4ae1-861b-2c41885b0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_hostname = \"brain-mri-ws-deploy.models.example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80dcaa-51ba-434c-94fe-9ff360849d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to caluclate intersection over union of prediction\n",
    "def iou(pred, label):\n",
    "    intersection = (pred * label).sum()\n",
    "    union = pred.sum() + label.sum() - intersection\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1\n",
    "    return intersection / union\n",
    "\n",
    "# Function to create tensor for image and mask\n",
    "def PairedToTensor(sample):\n",
    "    img, mask = sample\n",
    "    img = np.array(img)\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "    img = np.moveaxis(img, -1, 0)\n",
    "    mask = np.moveaxis(mask, -1, 0)\n",
    "    img, mask = torch.FloatTensor(img), torch.FloatTensor(mask)\n",
    "    img = img/255\n",
    "    mask = mask/255\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cdab9-bd9d-49cc-9028-871badb1bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_request(image, mask):\n",
    "    # Create tuple\n",
    "    sample = (image, mask)\n",
    "\n",
    "    # Create tensors from tuple\n",
    "    tensor_sample = PairedToTensor(sample)\n",
    "\n",
    "    # Create JSON payload for request\n",
    "    data = np.array(tensor_sample[0])\n",
    "    data_shape = list(data.shape)\n",
    "    request = {\n",
    "        \"inputs\": [{\n",
    "            \"name\": str(uuid.uuid4()),\n",
    "            \"shape\": data_shape,\n",
    "            \"datatype\": \"FP32\",\n",
    "            \"data\": np.round(data, 4).tolist()\n",
    "        }]\n",
    "    }\n",
    "    return tensor_sample, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a7f6a-4112-4849-b510-61eed6036b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image(tensor_sample):\n",
    "    # Show image that will be submitted\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.title(f'Submitted Image: ')\n",
    "    plt.imshow(tensor_sample[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f93b8-8bfc-4141-ba63-6a29f3f1eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image, mask, tensor_sample, request):\n",
    "    # Create GRPC request for Prediction (header, URL, payload)\n",
    "    url = str(\"http://\") + str(ingress_host) + \":\" + str(ingress_port) + \"/v2/models/\" + str(model_name) + \"/infer\"\n",
    "    headers = {'Host': service_hostname, \"Content-Type\": \"application/json\"}\n",
    "    payload = json.dumps(request)\n",
    "    \n",
    "   # Submit request, extract prediction in JSON, transform to Tensor\n",
    "    response = requests.post(url, data=payload, headers=headers)\n",
    "    output = response.json()\n",
    "\n",
    "    shape = [1,256,256]\n",
    "    values = output[\"outputs\"][0][\"data\"]\n",
    "    output = torch.Tensor(np.array(values).reshape(shape)) \n",
    "    \n",
    "    # # Display groundtruth and prediction mask, call iou function and display iou\n",
    "    # f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "    # axarr[0].imshow(tensor_sample[1].permute(1, 2, 0), alpha=0.4)\n",
    "    # axarr[0].title.set_text(f'Mask (Ground Truth):')\n",
    "    # axarr[1].imshow(output.permute(1, 2, 0), alpha=0.4)\n",
    "    # axarr[1].title.set_text(f'Mask (Prediction):')\n",
    "    # print(f'Intersection over Union (IoU): {iou(output, tensor_sample[1])}')\n",
    "    \n",
    "    # Display groundtruth and prediction overlaid on submitted image, call iou function and display iou\n",
    "    f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "    axarr[0].imshow(tensor_sample[0].permute(1, 2, 0))\n",
    "    axarr[0].imshow(tensor_sample[1].permute(1, 2, 0), alpha=0.4)\n",
    "    axarr[0].title.set_text(f'Full Image (Ground Truth):')\n",
    "    axarr[1].imshow(tensor_sample[0].permute(1, 2, 0))\n",
    "    axarr[1].imshow(output.permute(1, 2, 0), alpha=0.4)\n",
    "    axarr[1].title.set_text(f'Full Image (Prediction):')\n",
    "    print(f'Intersection over Union (IoU): {iou(output, tensor_sample[1])}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a79ab4",
   "metadata": {},
   "source": [
    "<h3>Step 2: Generate a prediction for a single image</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9551d33-579e-4538-8495-91b112dc5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and mask\n",
    "image = Image.open(\"../images/brain/TCGA_CS_6290_20000917/TCGA_CS_6290_20000917_10.tif\")\n",
    "mask = Image.open(\"../images/brain/TCGA_CS_6290_20000917/TCGA_CS_6290_20000917_10_mask.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae142d-3964-41d5-8cec-ed0eb1b1da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sample, request = create_request(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed9467-8dc7-47f5-8a7e-b710c32d8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_image(tensor_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ca3c5-03b8-4b1e-889b-b440489f4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction(image, mask, tensor_sample, request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042f5c7",
   "metadata": {},
   "source": [
    "<h3>Step 3: Generate a prediction for multiple images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b52c2-86f9-43c9-8d86-b9a729e2a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    [\"../images/brain/TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_13.tif\", \"../images/brain/TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_13_mask.tif\"],\n",
    "    [\"../images/brain/TCGA_CS_6669_20020102/TCGA_CS_6669_20020102_14.tif\", \"../images/brain/TCGA_CS_6669_20020102/TCGA_CS_6669_20020102_14_mask.tif\"],\n",
    "    [\"../images/brain/TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_10.tif\", \"../images/brain/TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_10_mask.tif\"],\n",
    "    [\"../images/brain/TCGA_CS_4942_19970222/TCGA_CS_4942_19970222_11.tif\", \"../images/brain/TCGA_CS_4942_19970222/TCGA_CS_4942_19970222_11_mask.tif\"],\n",
    "    [\"../images/brain/TCGA_CS_6665_20010817/TCGA_CS_6665_20010817_13.tif\", \"../images/brain/TCGA_CS_6665_20010817/TCGA_CS_6665_20010817_13_mask.tif\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5707b45-1d3b-45ef-971c-1df5b0a7d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in input_list:\n",
    "    image = Image.open(item[0])\n",
    "    mask = Image.open(item[1])\n",
    "    tensor_sample, request = create_request(image, mask)\n",
    "    get_prediction(image, mask, tensor_sample, request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16c9ed-7403-4ba4-ab62-191ea4bc2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

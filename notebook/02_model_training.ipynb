{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2469a97b-d52e-44b8-9bf4-4f6ad6ff1c15",
   "metadata": {},
   "source": [
    "<img src=\"img/hpe_logo.png\" alt=\"HPE Logo\" width=\"125\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f7792-b70f-4899-9561-cb1486067d83",
   "metadata": {},
   "source": [
    "# HPE ML Platform Workshop - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085a37c-dfd7-4ed3-aff3-bb2e52ce0b1c",
   "metadata": {},
   "source": [
    "<img src='img/platform_step02_training.png' width='1200'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4c5f9-decd-4aeb-a271-d934e55cea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from configparser import ConfigParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Torch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Image modules\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import functions for downloading data\n",
    "from utils.load_data import download_data\n",
    "\n",
    "# Import model util functions\n",
    "from utils.model_utils import set_seed, plot_example, PairedRandomHorizontalFlip, PairedRandomAffine, PairedToTensor, DoubleConv,  InConv, Down, Up, OutConv, UNet\n",
    "\n",
    "# Import MLDE packages\n",
    "from determined.experimental import client as det\n",
    "from determined import pytorch\n",
    "\n",
    "# Import MLDM packages\n",
    "import pachyderm_sdk\n",
    "from pachyderm_sdk.api import pfs\n",
    "from pachyderm_sdk.api.pfs import File, FileType\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"font-size:20px;color:maroon;font-family: 'Courier New';font-weight:bold\">\n",
    "    Important: set your MLDM Project name\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"brain-mri-workshop\" # change the project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f9c41-4f2e-41ef-899c-a6f5a7d6d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Set Variables\n",
    "config_obj = ConfigParser()\n",
    "config_obj.read(\"./utils/config.ini\")\n",
    "\n",
    "mldm_host = config_obj['PDK_INFO']['mldm_host']\n",
    "mldm_port = config_obj['PDK_INFO']['mldm_port']\n",
    "token = config_obj['PDK_INFO']['token']\n",
    "repo = config_obj['PDK_INFO']['repo']\n",
    "branch = config_obj['PDK_INFO']['branch']\n",
    "download_dir = config_obj['PDK_INFO']['download_dir']\n",
    "images_dir = config_obj['PDK_INFO']['images_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cc296-1c8e-4212-a1c7-38cbcd48c4bb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3228fee-a3b8-45e7-abd3-2d12b50aa1f7",
   "metadata": {},
   "source": [
    "<h2>Part 1: Processing, Loading and Analyzing Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe3369-110c-4067-9ffd-2981fc5ca601",
   "metadata": {},
   "source": [
    "<img src='img/platform_step01_data.png' width='1200'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a98820-f823-4d0f-92c8-d63340934a76",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cea34-2709-4caf-9a60-1fcb62124d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Instance\n",
    "mldm_client = pachyderm_sdk.Client(mldm_host, mldm_port, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc7667-e3ca-41c3-b837-69dd63fbb4aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List Files in the Repository\n",
    "files = []\n",
    "c_file = 0\n",
    "c_mask = 0\n",
    "c_folder = 0\n",
    "\n",
    "for file_info in mldm_client.pfs.walk_file(file=File.from_uri(f\"{project}/{repo}@{branch}\")):\n",
    "    f_path = file_info.file.path\n",
    "    print(f\"'{f_path}'\")\n",
    "    if \"_mask.tif\" in f_path:\n",
    "        c_mask += 1\n",
    "    elif \".tif\" in f_path:\n",
    "        c_file += 1\n",
    "    else:\n",
    "        c_folder += 1\n",
    "c_folder -= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--> Total Images: {c_file}\")\n",
    "print(f\"--> Total Masks: {c_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68f23d-2f02-49a7-87df-619b9bfec41f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Pre-Processed Files for local testing\n",
    "files = download_data(mldm_client, repo, branch, project, download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513eebd-9d7f-4595-bf3b-55c721370696",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = f\"{download_dir}/data1\"\n",
    "ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215bfce-6eac-4c62-be8a-bbc872fcb060",
   "metadata": {},
   "source": [
    "<h3> Data Exploration </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2021068-9549-4f81-ba39-a39a7b43a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:   \n",
    "    # data preprocessing\n",
    "    data_dir = ROOT\n",
    "    logdir = 'logdir'\n",
    "    validation_fraction = 0.15\n",
    "    test_fraction = 0.10\n",
    "    train_batch = 16\n",
    "    valid_batch = 32\n",
    "    test_batch = 32\n",
    "    \n",
    "    # model setup\n",
    "    input_dim = 256\n",
    "    input_ch = 3\n",
    "    output_dim = 256\n",
    "    output_ch = 1\n",
    "    \n",
    "    # training\n",
    "    seed = 21\n",
    "    learning_rate = 0.01\n",
    "    epochs = 10\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b66fc8-0788-44ee-9054-2bd83a76677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd68d6-c380-498d-9050-9ed4724828e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs, images, masks = [], [], []\n",
    "for root, folders, files in os.walk(Config.data_dir):\n",
    "    for file in files:\n",
    "        # save only images with corresponding masks\n",
    "        if 'mask'in file:\n",
    "            dirs.append(root.replace(Config.data_dir, ''))\n",
    "            masks.append(file)\n",
    "            images.append(file.replace('_mask', ''))\n",
    "\n",
    "PathDF = pd.DataFrame({'directory': dirs, 'images': images, 'masks': masks})\n",
    "PathDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9ca97-42e4-44d3-a948-eeae595cf4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2rest = Config.validation_fraction + Config.test_fraction\n",
    "test2valid = Config.validation_fraction/train2rest\n",
    "\n",
    "train_df, rest = train_test_split(\n",
    "    PathDF, random_state=Config.seed,\n",
    "    test_size=train2rest\n",
    ")\n",
    "\n",
    "test_df, valid_df = train_test_split(\n",
    "    rest, random_state=Config.seed,\n",
    "    test_size=test2valid\n",
    ")\n",
    "\n",
    "print('Train:', train_df.shape[0])\n",
    "print('Valid:', valid_df.shape[0])\n",
    "print('Test:', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0041d3-f442-4cc6-a39a-2bc5f24821d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(Config.data_dir, 4, test_df)\n",
    "plot_example(Config.data_dir, 8, test_df)\n",
    "plot_example(Config.data_dir, 13, test_df)\n",
    "plot_example(Config.data_dir, 16, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81102b-4ff4-4f27-b801-588e7b802b4d",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a81a7b-f9a7-4118-aef5-ce8f0ad06372",
   "metadata": {},
   "source": [
    "# Usual Model Training Process (without MLDE)\n",
    "\n",
    "<small> <i> Source: https://github.com/MedMNIST/experiments/blob/main/MedMNIST2D/train_and_eval_pytorch.py </i> </small> <br/>\n",
    "<small> Full Model Porting tutorial: https://www.youtube.com/watch?v=DHm8FdKN3x0 </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dd386-2c54-478e-a03c-69845ecddbf0",
   "metadata": {},
   "source": [
    "<img src=\"./img/02_mlde/06.png\" alt=\"HP and Device Settings\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ab39f-6da2-4253-8692-7e1043336fc7",
   "metadata": {},
   "source": [
    "<img src=\"./img/02_mlde/07.png\" alt=\"Metrics Settings\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a1aa8-f878-4f9b-aeb1-1205a2d68c34",
   "metadata": {},
   "source": [
    "<img src=\"./img/02_mlde/08.png\" alt=\"Epoch loop\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436a860-c9ae-47cd-b6f3-04a863e46a5d",
   "metadata": {},
   "source": [
    "## But wait, there's more:\n",
    "- Hyperparameter Tuning\n",
    "- Distributed Training\n",
    "- Checkpoint Management\n",
    "- Reproducibility\n",
    "- Auditability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce61b4-fc3c-43f5-80b9-69535ec3f9e0",
   "metadata": {},
   "source": [
    "## Focusing on What Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66581aad-6363-4501-bfd1-7bc791851fb9",
   "metadata": {},
   "source": [
    "<img src=\"./img/02_mlde/10.png\" alt=\"MLDE BYOM\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5689eeb-1d14-48ad-9ff3-84b0d9522b79",
   "metadata": {},
   "source": [
    "<img src=\"./img/02_mlde/09.png\" alt=\"Experiment Components\" width=800></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902893cb-871a-4ea9-9edc-7d833eee4cb7",
   "metadata": {},
   "source": [
    "### Inspect configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be23095-a8f4-43ed-9463-00ad4f2ec440",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./experiment/const.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373de09-cf83-49c7-afc8-c3234d615954",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"font-size:20px;color:maroon;font-family: 'Courier New';font-weight:bold\">\n",
    "    Important: Edit the <i>const.yaml</i> file and review the values for:\n",
    "    <ul><li>workspace</li>\n",
    "        <li>project</li>\n",
    "        <li>The MLDM config data in the 'pachyderm' block</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c645f3-9236-4466-b5c7-c408581bbf1f",
   "metadata": {},
   "source": [
    "### Create a new Experiment using the const.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9b3c0-7b15-449e-818c-b1f136bbc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = det.create_experiment(config=\"./experiment/const.yaml\", model_dir=\"./experiment/\")\n",
    "print(f\"started experiment {exp.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377e473-88a1-4a0d-878c-73fd52c98b09",
   "metadata": {},
   "source": [
    "### (optional) Wait for Experiment to complete and print exit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31906254-8a25-4fe8-9122-5dc6b1b93ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_status = exp.wait()\n",
    "print(f\"experiment completed with status {exit_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74634ce6-df8a-47d3-9f0f-d0019d4dc0e0",
   "metadata": {},
   "source": [
    "### Get the best Checkpoint from the Experiment and print uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c3541-0a8a-4344-ad33-061768ebfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = exp.top_checkpoint()\n",
    "best_checkpoint_uuid = best_checkpoint.uuid\n",
    "print(f\"Best checkpoint was {best_checkpoint_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f978cd5-be20-4f5c-ad8f-65c456371e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = exp.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd37113-a747-46c3-9cef-1db1528d8ab5",
   "metadata": {},
   "source": [
    "### Download the checkpoint and load it as new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26746a0-a867-44c3-9c34-8a54dad050d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = det.get_experiment(experiment_id).top_checkpoint()\n",
    "path = checkpoint.download()\n",
    "mlde_model = pytorch.load_trial_from_checkpoint_path(path).model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9ed9b-ea81-495e-91ca-c144d21cdd0d",
   "metadata": {},
   "source": [
    "### Generate a few predictions to test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d80aab-5c2b-4254-958e-d1242c1b1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0ed0d-a7b5-410b-aebc-08190161e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_new_predictions(data_dir, model, idx, device, test_df):\n",
    "    base_path = data_dir + '/' +  test_df['directory'].iloc[idx]\n",
    "    img_path = os.path.join(base_path, test_df['images'].iloc[idx])\n",
    "    mask_path = os.path.join(base_path, test_df['masks'].iloc[idx])\n",
    "    \n",
    "    size = 256\n",
    "    shape = [1, 256, 256]\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    transforms = [torchvision.transforms.ToTensor()]\n",
    "    try:\n",
    "        width, height = size\n",
    "    except TypeError:\n",
    "        width = height = size\n",
    "    scale = min(width / img.width, height / img.height)\n",
    "    new_width, new_height = int(img.width * scale), int(img.height * scale)\n",
    "    diff_width, diff_height = width - new_width, height - new_height\n",
    "    resize = torchvision.transforms.Resize(size=(new_height, new_width))\n",
    "    pad = torchvision.transforms.Pad(\n",
    "        padding=(\n",
    "            diff_width // 2,\n",
    "            diff_height // 2,\n",
    "            diff_width // 2 + diff_width % 2,\n",
    "            diff_height // 2 + diff_height % 2,\n",
    "        )\n",
    "    )\n",
    "    transforms = [resize, pad] + transforms\n",
    "    transformation = torchvision.transforms.Compose(transforms)\n",
    "    x = transformation(img)\n",
    "    x = torch.stack([x], 0)\n",
    "    \n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    preds = model(x)\n",
    "  \n",
    "    pred_values = torch.tensor(preds[0], requires_grad=True)\n",
    "    pred_values = pred_values.detach().numpy()\n",
    "    pred_output = torch.Tensor(np.array(pred_values).reshape(shape))    \n",
    "\n",
    "    plot_images = {'Image': img, \n",
    "                   'Mask': mask, \n",
    "                   'Predicted Mask': pred_output.permute(1, 2, 0)}\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16,4))\n",
    "    for i, key in enumerate(plot_images.keys()):\n",
    "        ax[i].imshow(plot_images[key])\n",
    "        ax[i].set_title(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613f380-b8d4-4317-8aac-962d727f06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new_predictions(Config.data_dir, mlde_model, 4, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, mlde_model, 8, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, mlde_model, 13, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, mlde_model, 16, Config.device, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Distributed Training Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58ac6f-affe-4187-9fe6-7ac147e15640",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./experiment/distributed.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"font-size:20px;color:maroon;font-family: 'Courier New';font-weight:bold\">\n",
    "    Important: Edit the <i>distributed.yaml</i> file and set the values for:\n",
    "    <ul><li>workspace</li>\n",
    "        <li>project</li>\n",
    "        <li>The MLDM config data in the 'pachyderm' block</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new Experiment using the distributed.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = det.create_experiment(config=\"./experiment/distributed.yaml\", model_dir=\"./experiment/\")\n",
    "print(f\"started experiment {exp.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Wait for Experiment to complete and print exit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_status = exp.wait()\n",
    "print(f\"experiment completed with status {exit_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best Checkpoint from the Experiment and print uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = exp.top_checkpoint()\n",
    "best_checkpoint_uuid = best_checkpoint.uuid\n",
    "print(f\"Best checkpoint was {best_checkpoint_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = exp.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the checkpoint and load it as new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = det.get_experiment(experiment_id).top_checkpoint()\n",
    "path = checkpoint.download()\n",
    "dist_model = pytorch.load_trial_from_checkpoint_path(path).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a few predictions to test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new_predictions(Config.data_dir, dist_model, 4, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, dist_model, 8, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, dist_model, 13, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, dist_model, 16, Config.device, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c0a00-c4d8-4c1d-9b68-f0ee179a0d62",
   "metadata": {},
   "source": [
    "## Run a Hyperparameter Search Training Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126481ac-9634-4521-91f9-ad1c729db631",
   "metadata": {},
   "source": [
    "### Inspect configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942092a-e6e9-46e5-9ce0-041173e3aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./experiment/search.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f2bcc6-a884-468a-9040-52d2f237a1c2",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"font-size:20px;color:maroon;font-family: 'Courier New';font-weight:bold\">\n",
    "    Important: Edit the <i>search.yaml</i> file and set the values for:\n",
    "    <ul><li>workspace</li>\n",
    "        <li>project</li>\n",
    "        <li>The MLDM config data in the 'pachyderm' block</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the Trial Plan before creating the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!det preview-search ./experiment/search.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f2c9c-55ba-432d-8c12-a2a86ec5809d",
   "metadata": {},
   "source": [
    "### Create a new Experiment using the search.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5a1c2-d084-4a5e-b6ae-162f395f79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = det.create_experiment(config=\"./experiment/search.yaml\", model_dir=\"./experiment/\")\n",
    "print(f\"started experiment {exp.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Wait for Experiment to complete and print exit status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4236a-c359-4659-803c-e46e0caa3021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exit_status = exp.wait()\n",
    "#print(f\"experiment completed with status {exit_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best Checkpoint from the Experiment and print uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = exp.top_checkpoint()\n",
    "best_checkpoint_uuid = best_checkpoint.uuid\n",
    "print(f\"Best checkpoint was {best_checkpoint_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = exp.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the checkpoint and load it as new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = det.get_experiment(experiment_id).top_checkpoint()\n",
    "path = checkpoint.download()\n",
    "hp_model = pytorch.load_trial_from_checkpoint_path(path).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a few predictions to test the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_new_predictions(Config.data_dir, hp_model, 4, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, hp_model, 8, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, hp_model, 13, Config.device, test_df)\n",
    "plot_new_predictions(Config.data_dir, hp_model, 16, Config.device, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350aa1c-fc53-4202-a4cb-df2b31bf261a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef5193-8cf1-46ce-bd9a-27186ca0c653",
   "metadata": {},
   "source": [
    "<h2> Part 3: Deploying Models to Production </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a118db0-2f21-408f-b446-5a8e85a3f062",
   "metadata": {},
   "source": [
    "<img src='img/platform_step03_deployment.png' width='1200'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b0c2b-61d3-4fa9-93ee-b775d0bcaa35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Predictions from the Production Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a268136-5bfb-4feb-95f4-d461caf2ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978861c-433d-4be1-ad45-721cfb077fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config_obj['PDK_INFO']['model_name']\n",
    "ingress_host = config_obj['PDK_INFO']['ingress_host']\n",
    "ingress_port = config_obj['PDK_INFO']['ingress_port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the service hostname to your deployment\n",
    "service_hostname = \"brain-mri-ws-deploy.models.example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f3dd6-c119-4ff4-be2c-0c6347a99012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to caluclate intersection over union of prediction\n",
    "def iou(pred, label):\n",
    "    intersection = (pred * label).sum()\n",
    "    union = pred.sum() + label.sum() - intersection\n",
    "    if pred.sum() == 0 and label.sum() == 0:\n",
    "        return 1\n",
    "    return intersection / union\n",
    "\n",
    "# Function to create tensor for image and mask\n",
    "def PairedToTensor(sample):\n",
    "    img, mask = sample\n",
    "    img = np.array(img)\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "    img = np.moveaxis(img, -1, 0)\n",
    "    mask = np.moveaxis(mask, -1, 0)\n",
    "    img, mask = torch.FloatTensor(img), torch.FloatTensor(mask)\n",
    "    img = img/255\n",
    "    mask = mask/255\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f709c2e-80a1-4758-aa8b-42412d87672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and mask\n",
    "image = Image.open(\"data/data1/TCGA_CS_6290_20000917/TCGA_CS_6290_20000917_10.tif\")\n",
    "mask = Image.open(\"data/data1/TCGA_CS_6290_20000917/TCGA_CS_6290_20000917_10_mask.tif\")\n",
    "\n",
    "# Create tuple\n",
    "sample = (image, mask)\n",
    "\n",
    "# Create tensors from tuple\n",
    "tensor_sample = PairedToTensor(sample)\n",
    "\n",
    "# Create JSON payload for request\n",
    "data = np.array(tensor_sample[0])\n",
    "data_shape = list(data.shape)\n",
    "request = {\n",
    "    \"inputs\": [{\n",
    "        \"name\": str(uuid.uuid4()),\n",
    "        \"shape\": data_shape,\n",
    "        \"datatype\": \"FP32\",\n",
    "        \"data\": np.round(data, 4).tolist()\n",
    "    }]\n",
    "}\n",
    "\n",
    "# Show image that will be submitted\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title(f'Submitted Image: ')\n",
    "plt.imshow(tensor_sample[0].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create request for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e871c26-748a-44d1-bf28-d4f47c0f2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = str(\"http://\") + str(ingress_host) + \":\" + str(ingress_port) + \"/v1/models/\" + str(model_name) + \":predict\"\n",
    "headers = {'Host': service_hostname, \"Content-Type\": \"application/json\"}\n",
    "payload = json.dumps(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4f2f8-8e30-42b9-93eb-09845b6b025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit request, extract prediction in JSON, transform to Tensor\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "output = response.json()\n",
    "\n",
    "shape = [1,256,256]\n",
    "values = output[\"outputs\"][0][\"data\"]\n",
    "output = torch.Tensor(np.array(values).reshape(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ground truth and prediction, call IoU function and display IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afacf51-e437-4b2b-94f8-bb810cf432ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "axarr[0].imshow(tensor_sample[1].permute(1, 2, 0), alpha=0.8)\n",
    "axarr[0].title.set_text(f'Mask (Ground Truth):')\n",
    "axarr[1].imshow(output.permute(1, 2, 0), alpha=0.8)\n",
    "axarr[1].title.set_text(f'Mask (Prediction):')\n",
    "print(f'Intersection over Union (IoU): {iou(output, tensor_sample[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63447b06-24bc-4c02-8df9-bb32d473ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display groundtruth and prediction overlaid on submitted image, call iou function and display iou\n",
    "f, axarr = plt.subplots(1,2, figsize=(15, 15))\n",
    "axarr[0].imshow(tensor_sample[0].permute(1, 2, 0))\n",
    "axarr[0].imshow(tensor_sample[1].permute(1, 2, 0), alpha=0.4)\n",
    "axarr[0].title.set_text(f'Full Image (Ground Truth):')\n",
    "axarr[1].imshow(tensor_sample[0].permute(1, 2, 0))\n",
    "axarr[1].imshow(output.permute(1, 2, 0), alpha=0.4)\n",
    "axarr[1].title.set_text(f'Full Image (Prediction):')\n",
    "print(f'Intersection over Union (IoU): {iou(output, tensor_sample[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500af3a-e14e-4293-85c8-453d567ae63a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931302a-c0c7-4880-bdad-b2a02d7174ab",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d1965-34be-4a8f-ad30-c3e203403ba3",
   "metadata": {},
   "source": [
    "<h2> Bringing It All Together </h2>\n",
    "<img src='img/big_picture.png' width='1200'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! The Model Training lab is completed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
